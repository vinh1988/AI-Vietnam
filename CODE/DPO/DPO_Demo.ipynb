{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec98033",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DPO\" data-toc-modified-id=\"DPO-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DPO</a></span><ul class=\"toc-item\"><li><span><a href=\"#SFT\" data-toc-modified-id=\"SFT-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>SFT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Init-model\" data-toc-modified-id=\"Init-model-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Init model</a></span></li><li><span><a href=\"#Prepare-dataset\" data-toc-modified-id=\"Prepare-dataset-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Prepare dataset</a></span></li></ul></li><li><span><a href=\"#DPO\" data-toc-modified-id=\"DPO-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>DPO</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-SFT-model\" data-toc-modified-id=\"Load-SFT-model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Load SFT model</a></span></li><li><span><a href=\"#Prepare-dataset\" data-toc-modified-id=\"Prepare-dataset-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Prepare dataset</a></span></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Inference</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b285d",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab04f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T04:01:43.611418Z",
     "start_time": "2024-02-17T04:01:43.609001Z"
    }
   },
   "source": [
    "## SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bc579",
   "metadata": {},
   "source": [
    "### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494e39a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:40:50.898815Z",
     "start_time": "2024-02-24T12:40:48.452232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/light/miniconda3/envs/workspace/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3bd2e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:40:51.976722Z",
     "start_time": "2024-02-24T12:40:51.974655Z"
    }
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe54c8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-24T12:39:58.423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7. FA = False.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    cache_dir = \"cached\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1123ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:20:02.152335Z",
     "start_time": "2024-02-17T01:20:01.823505Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc612c6d",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea2cd8",
   "metadata": {},
   "source": [
    "Source: \n",
    "- https://github.com/adithya-s-k/LLM-Alchemy-Chamber/blob/main/LLMs/Mistral-7b/Mistral_Colab_Finetune_ipynb_Colab_Final.ipynb?source=post_page-----0f39647b20fe--------------------------------\n",
    "- https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing#scrollTo=oF63zQqNlNJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149454ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:40:35.865302Z",
     "start_time": "2024-02-24T12:40:35.653466Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m EOS_TOKEN \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9573b166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:20:28.542460Z",
     "start_time": "2024-02-17T01:20:11.387602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'instruction', 'output', 'input'],\n",
       "    num_rows: 121959\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"TokenBender/code_instructions_122k_alpaca_style\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd2e01f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:20:50.367370Z",
     "start_time": "2024-02-17T01:20:43.514291Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████████████████████████████████████████████████████████████| 121959/121959 [00:02<00:00, 55363.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(data_point):\n",
    "    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer\n",
    "\n",
    "    :param data_point: dict: Data point\n",
    "    :return: dict: tokenzed prompt\n",
    "    \"\"\"\n",
    "    prefix_text = 'Below is an instruction that describes a task. Write a response that ' \\\n",
    "               'appropriately completes the request.\\n\\n'\n",
    "    # Samples with additional context into.\n",
    "    if data_point['input']:\n",
    "        text = f\"\"\"[INST]{prefix_text} {data_point[\"instruction\"]} here are the inputs {data_point[\"input\"]} [/INST]{data_point[\"output\"]} \"\"\" + EOS_TOKEN\n",
    "    # Without\n",
    "    else:\n",
    "        text = f\"\"\"[INST]{prefix_text} {data_point[\"instruction\"]} [/INST]{data_point[\"output\"]} \"\"\" + EOS_TOKEN\n",
    "    return text\n",
    "\n",
    "# add the \"prompt\" column in the dataset\n",
    "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "dataset = dataset.add_column(\"prompt\", text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ebf2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:21:02.584712Z",
     "start_time": "2024-02-17T01:20:51.412723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████| 121959/121959 [00:11<00:00, 10984.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9effe324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:21:03.250310Z",
     "start_time": "2024-02-17T01:21:03.223269Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.5)\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66670ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:25:54.568557Z",
     "start_time": "2024-02-15T15:25:54.565614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Using Python, create a program to get the grade corresponding to a percentage. ### Input: No input ### Output: def grade(percentage):\\n    if percentage >= 90:\\n        return 'A'\\n    elif percentage >= 80:\\n        return 'B'\\n    elif percentage >= 70:\\n        return 'C'\\n    elif percentage >= 60:\\n        return 'D'\\n    else:\\n        return 'F'\", 'instruction': 'Using Python, create a program to get the grade corresponding to a percentage.', 'output': \"def grade(percentage):\\n    if percentage >= 90:\\n        return 'A'\\n    elif percentage >= 80:\\n        return 'B'\\n    elif percentage >= 70:\\n        return 'C'\\n    elif percentage >= 60:\\n        return 'D'\\n    else:\\n        return 'F'\", 'input': '', 'prompt': \"[INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n Using Python, create a program to get the grade corresponding to a percentage. [/INST]def grade(percentage):\\n    if percentage >= 90:\\n        return 'A'\\n    elif percentage >= 80:\\n        return 'B'\\n    elif percentage >= 70:\\n        return 'C'\\n    elif percentage >= 60:\\n        return 'D'\\n    else:\\n        return 'F'</s>\", 'input_ids': [1, 733, 16289, 28793, 20548, 336, 349, 396, 13126, 369, 13966, 264, 3638, 28723, 12018, 264, 2899, 369, 6582, 1999, 2691, 274, 272, 2159, 28723, 13, 13, 9616, 21366, 28725, 2231, 264, 2007, 298, 625, 272, 12146, 7606, 298, 264, 13822, 28723, 733, 28748, 16289, 28793, 1270, 12146, 28732, 18799, 465, 1329, 13, 2287, 513, 13822, 3966, 28705, 28774, 28734, 28747, 13, 5390, 604, 464, 28741, 28742, 13, 2287, 16422, 13822, 3966, 28705, 28783, 28734, 28747, 13, 5390, 604, 464, 28760, 28742, 13, 2287, 16422, 13822, 3966, 28705, 28787, 28734, 28747, 13, 5390, 604, 464, 28743, 28742, 13, 2287, 16422, 13822, 3966, 28705, 28784, 28734, 28747, 13, 5390, 604, 464, 28757, 28742, 13, 2287, 1112, 28747, 13, 5390, 604, 464, 28765, 28742, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for data in train_data:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d62da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T01:21:30.534796Z",
     "start_time": "2024-02-17T01:21:30.531272Z"
    }
   },
   "outputs": [],
   "source": [
    "train_arg = TrainingArguments(\n",
    "    per_device_train_batch_size = 16,\n",
    "    gradient_accumulation_steps = 4,\n",
    "#     per_device_eval_batch_size = 1,\n",
    "    warmup_ratio=0.03,\n",
    "#     warmup_steps = 10,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=10,\n",
    "#     max_steps = 100,\n",
    "    num_train_epochs=1,\n",
    "    save_steps= 50,\n",
    "    learning_rate = 2e-4,\n",
    "    fp16 = not torch.cuda.is_bf16_supported(),\n",
    "    bf16 = torch.cuda.is_bf16_supported(),\n",
    "    logging_steps = 1,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.05,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    seed = 3407,\n",
    "    output_dir = \"sft_mistral_1\",\n",
    "    report_to = \"none\", # Disable reporting to WandB\n",
    "#     run_name= \"sft_mistral_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71b9cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T03:57:12.811323Z",
     "start_time": "2024-02-17T01:21:33.861926Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 6407 examples [00:12, 523.96 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 2:33:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.947100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.599500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.569200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.517200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.529300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.520400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.495500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.494300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.506200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.540700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.509900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.505900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.502700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.480200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.503800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.531300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.513900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.511400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.484300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.490700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.517200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.5690591669082642, metrics={'train_runtime': 9326.1293, 'train_samples_per_second': 0.687, 'train_steps_per_second': 0.011, 'total_flos': 5.625035989450752e+17, 'train_loss': 0.5690591669082642, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "#     eval_dataset=test_data,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing = True,\n",
    "    args = train_arg\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbb01c",
   "metadata": {},
   "source": [
    "## DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f20ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:41:19.820963Z",
     "start_time": "2024-02-24T12:41:19.818140Z"
    }
   },
   "outputs": [],
   "source": [
    "from unsloth import PatchDPOTrainer\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22329b",
   "metadata": {},
   "source": [
    "### Load SFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65c05e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:48:58.065104Z",
     "start_time": "2024-02-17T05:48:54.234010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7. FA = False.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n",
      "Unsloth 2024.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"/mnt/d/Deep_learning/LLM/DPO/sft_mistral_1/checkpoint-100\", # YOUR MODEL DIRECTORY YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "        cache_dir = \"cached\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7e21cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:01.151976Z",
     "start_time": "2024-02-17T05:49:01.149841Z"
    }
   },
   "outputs": [],
   "source": [
    "PatchDPOTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1aee5",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c85b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:41:23.867198Z",
     "start_time": "2024-02-24T12:41:23.864476Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8573d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:05.305827Z",
     "start_time": "2024-02-17T05:49:05.303069Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49530f33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:23.822769Z",
     "start_time": "2024-02-17T05:49:08.081153Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"Intel/orca_dpo_pairs\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a166bf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:26.566359Z",
     "start_time": "2024-02-17T05:49:26.562870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['system', 'question', 'chosen', 'rejected'],\n",
       "    num_rows: 12859\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3975c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:30.184329Z",
     "start_time": "2024-02-17T05:49:29.831315Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_dataset(data_point):\n",
    "    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer\n",
    "\n",
    "    :param data_point: dict: Data point\n",
    "    :return: dict: tokenzed prompt\n",
    "    \"\"\"\n",
    "    prefix_text = 'Below is an instruction that describes a task. Write a response that ' \\\n",
    "               'appropriately completes the request.\\n\\n'\n",
    "    # Samples with additional context into.\n",
    "    if len(data_point['system'])>0:\n",
    "        prompt = f\"\"\"[INST]{data_point['system']} {data_point[\"question\"]} [/INST]\"\"\"\n",
    "        \n",
    "    # Without\n",
    "    else:\n",
    "        prompt = f\"\"\"[INST]{prefix_text} {data_point[\"question\"]} [/INST]\"\"\"\n",
    "    chosen = f\"\"\"{data_point[\"chosen\"]} \"\"\" + EOS_TOKEN\n",
    "    reject = f\"\"\"{data_point[\"rejected\"]} \"\"\" + EOS_TOKEN\n",
    "    return {\n",
    "        \"text_prompt\":prompt,\n",
    "        \"text_chosen\":chosen,\n",
    "        \"text_reject\": reject\n",
    "   }\n",
    "\n",
    "# format dataset to the correct dpo format column in the dataset\n",
    "formatted_list = [format_dataset(data_point) for data_point in raw_datasets]\n",
    "formatted_dataset = Dataset.from_list(formatted_list)\n",
    "#free memory\n",
    "del raw_datasets\n",
    "formatted_dataset = formatted_dataset.rename_columns(\n",
    "    {\"text_prompt\": \"prompt\", \"text_chosen\": \"chosen\", \"text_reject\": \"rejected\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2efecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:32.859895Z",
     "start_time": "2024-02-17T05:49:32.857360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 12859\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086b80ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:49:34.949059Z",
     "start_time": "2024-02-17T05:49:34.945582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " You will be given a definition of a task first, then some input of the task.\n",
      "This task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\n",
      "\n",
      "AFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\n",
      "Output: [/INST]\n",
      "[\n",
      "  [\"AFC Ajax (amateurs)\", \"has ground\", \"Sportpark De Toekomst\"],\n",
      "  [\"Ajax Youth Academy\", \"plays at\", \"Sportpark De Toekomst\"]\n",
      "] </s>\n",
      " Sure, I'd be happy to help! Here are the RDF triplets for the input sentence:\n",
      "\n",
      "[AFC Ajax (amateurs), hasGround, Sportpark De Toekomst]\n",
      "[Ajax Youth Academy, playsAt, Sportpark De Toekomst]\n",
      "\n",
      "Explanation:\n",
      "\n",
      "* AFC Ajax (amateurs) is the subject of the first triplet, and hasGround is the predicate that describes the relationship between AFC Ajax (amateurs) and Sportpark De Toekomst.\n",
      "* Ajax Youth Academy is the subject of the second triplet, and playsAt is the predicate that describes the relationship between Ajax Youth Academy and Sportpark De Toekomst.\n",
      "\n",
      "Note that there may be other possible RDF triplets that could be derived from the input sentence, but the above triplets capture the main relationships present in the sentence. </s>\n"
     ]
    }
   ],
   "source": [
    "for item in formatted_dataset:\n",
    "    print(item['prompt'])\n",
    "    print(item['chosen'])\n",
    "    print(item['rejected'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8580b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T05:50:11.609259Z",
     "start_time": "2024-02-17T05:49:38.048115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/light/miniconda3/envs/workspace/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:314: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 12859/12859 [00:33<00:00, 383.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model = model,\n",
    "    ref_model = None,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 5e-6,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 20,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.0,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        output_dir = \"dpo_mistral_1\",\n",
    "    ),\n",
    "    beta = 0.1,\n",
    "    train_dataset = formatted_dataset,\n",
    "    # eval_dataset = raw_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = max_seq_length,\n",
    "    max_prompt_length = 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a3d8711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:32:59.740655Z",
     "start_time": "2024-02-17T05:50:46.137980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryuugamineraito\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/Deep_learning/LLM/DPO/wandb/run-20240217_125047-47lplus2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryuugamineraito/huggingface/runs/47lplus2' target=\"_blank\">incandescent-rocket-54</a></strong> to <a href='https://wandb.ai/ryuugamineraito/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryuugamineraito/huggingface' target=\"_blank\">https://wandb.ai/ryuugamineraito/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryuugamineraito/huggingface/runs/47lplus2' target=\"_blank\">https://wandb.ai/ryuugamineraito/huggingface/runs/47lplus2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='803' max='803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [803/803 5:41:43, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.182100</td>\n",
       "      <td>9.051140</td>\n",
       "      <td>9.568521</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>-0.517381</td>\n",
       "      <td>-201.433014</td>\n",
       "      <td>-195.275757</td>\n",
       "      <td>-1.295759</td>\n",
       "      <td>-0.597259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.489600</td>\n",
       "      <td>9.328835</td>\n",
       "      <td>8.620270</td>\n",
       "      <td>0.559375</td>\n",
       "      <td>0.708566</td>\n",
       "      <td>-190.025940</td>\n",
       "      <td>-179.856842</td>\n",
       "      <td>-1.259751</td>\n",
       "      <td>-0.483397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>9.182238</td>\n",
       "      <td>8.385566</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.796672</td>\n",
       "      <td>-194.622299</td>\n",
       "      <td>-164.885361</td>\n",
       "      <td>-1.187251</td>\n",
       "      <td>-0.483916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.170800</td>\n",
       "      <td>9.359728</td>\n",
       "      <td>7.815445</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>1.544284</td>\n",
       "      <td>-201.498459</td>\n",
       "      <td>-168.936249</td>\n",
       "      <td>-1.141978</td>\n",
       "      <td>-0.321024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.956600</td>\n",
       "      <td>8.970770</td>\n",
       "      <td>6.845100</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>2.125670</td>\n",
       "      <td>-205.834259</td>\n",
       "      <td>-160.862000</td>\n",
       "      <td>-1.150811</td>\n",
       "      <td>-0.378033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.576400</td>\n",
       "      <td>8.969905</td>\n",
       "      <td>5.447421</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>3.522483</td>\n",
       "      <td>-243.900833</td>\n",
       "      <td>-190.908615</td>\n",
       "      <td>-1.085047</td>\n",
       "      <td>-0.335189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>8.654298</td>\n",
       "      <td>3.529065</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>5.125234</td>\n",
       "      <td>-239.623978</td>\n",
       "      <td>-182.289566</td>\n",
       "      <td>-0.880257</td>\n",
       "      <td>-0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>8.798752</td>\n",
       "      <td>2.058996</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>6.739756</td>\n",
       "      <td>-254.018600</td>\n",
       "      <td>-178.985718</td>\n",
       "      <td>-0.885073</td>\n",
       "      <td>-0.053368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>8.441160</td>\n",
       "      <td>-0.207025</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>8.648185</td>\n",
       "      <td>-292.706604</td>\n",
       "      <td>-177.333054</td>\n",
       "      <td>-0.855067</td>\n",
       "      <td>0.114650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>7.508460</td>\n",
       "      <td>-2.631932</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>10.140392</td>\n",
       "      <td>-318.287598</td>\n",
       "      <td>-196.642792</td>\n",
       "      <td>-0.678211</td>\n",
       "      <td>0.163436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>7.387518</td>\n",
       "      <td>-3.912784</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>11.300303</td>\n",
       "      <td>-308.527954</td>\n",
       "      <td>-177.254578</td>\n",
       "      <td>-0.691197</td>\n",
       "      <td>0.144077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>7.347479</td>\n",
       "      <td>-6.882282</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>14.229761</td>\n",
       "      <td>-355.112000</td>\n",
       "      <td>-188.083328</td>\n",
       "      <td>-0.454488</td>\n",
       "      <td>0.502971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>6.904913</td>\n",
       "      <td>-7.368163</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>14.273076</td>\n",
       "      <td>-365.459534</td>\n",
       "      <td>-217.095383</td>\n",
       "      <td>-0.449868</td>\n",
       "      <td>0.412279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>6.291568</td>\n",
       "      <td>-8.795122</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>15.086688</td>\n",
       "      <td>-371.850189</td>\n",
       "      <td>-204.266937</td>\n",
       "      <td>-0.241083</td>\n",
       "      <td>0.684575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>6.814032</td>\n",
       "      <td>-8.535282</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>15.349314</td>\n",
       "      <td>-366.479645</td>\n",
       "      <td>-194.450317</td>\n",
       "      <td>-0.334054</td>\n",
       "      <td>0.491141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>6.791338</td>\n",
       "      <td>-9.114085</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>15.905423</td>\n",
       "      <td>-372.523041</td>\n",
       "      <td>-199.925705</td>\n",
       "      <td>-0.366881</td>\n",
       "      <td>0.532427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>6.949622</td>\n",
       "      <td>-9.414212</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>16.363834</td>\n",
       "      <td>-366.383850</td>\n",
       "      <td>-187.622864</td>\n",
       "      <td>-0.292631</td>\n",
       "      <td>0.605147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>7.057099</td>\n",
       "      <td>-10.314448</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>17.371546</td>\n",
       "      <td>-372.668396</td>\n",
       "      <td>-188.575180</td>\n",
       "      <td>-0.369904</td>\n",
       "      <td>0.591875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>6.626616</td>\n",
       "      <td>-10.657803</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>17.284418</td>\n",
       "      <td>-397.578827</td>\n",
       "      <td>-210.814941</td>\n",
       "      <td>-0.278216</td>\n",
       "      <td>0.676022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>7.120962</td>\n",
       "      <td>-10.253636</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>17.374599</td>\n",
       "      <td>-378.995056</td>\n",
       "      <td>-199.039139</td>\n",
       "      <td>-0.105206</td>\n",
       "      <td>0.841688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>6.328309</td>\n",
       "      <td>-12.679837</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>19.008144</td>\n",
       "      <td>-415.971375</td>\n",
       "      <td>-226.692062</td>\n",
       "      <td>-0.126074</td>\n",
       "      <td>0.787327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>6.449947</td>\n",
       "      <td>-11.611557</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>18.061504</td>\n",
       "      <td>-393.860443</td>\n",
       "      <td>-202.140320</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.883016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>6.559916</td>\n",
       "      <td>-11.982170</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>18.542088</td>\n",
       "      <td>-393.642761</td>\n",
       "      <td>-192.649307</td>\n",
       "      <td>0.026599</td>\n",
       "      <td>0.987415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>6.669753</td>\n",
       "      <td>-13.487432</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>20.157185</td>\n",
       "      <td>-418.944916</td>\n",
       "      <td>-196.972244</td>\n",
       "      <td>-0.010882</td>\n",
       "      <td>0.982715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>6.835725</td>\n",
       "      <td>-12.537959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.373684</td>\n",
       "      <td>-401.950958</td>\n",
       "      <td>-193.496414</td>\n",
       "      <td>-0.129530</td>\n",
       "      <td>0.889540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>6.329516</td>\n",
       "      <td>-12.917702</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>19.247219</td>\n",
       "      <td>-418.700195</td>\n",
       "      <td>-195.851959</td>\n",
       "      <td>-0.063018</td>\n",
       "      <td>0.993423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>6.393374</td>\n",
       "      <td>-13.576998</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>19.970371</td>\n",
       "      <td>-422.438812</td>\n",
       "      <td>-207.231293</td>\n",
       "      <td>-0.125449</td>\n",
       "      <td>0.867161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>6.537346</td>\n",
       "      <td>-13.478182</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>20.015530</td>\n",
       "      <td>-421.787659</td>\n",
       "      <td>-208.176300</td>\n",
       "      <td>0.068240</td>\n",
       "      <td>1.093267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>6.540387</td>\n",
       "      <td>-14.262854</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>20.803242</td>\n",
       "      <td>-424.946289</td>\n",
       "      <td>-184.695801</td>\n",
       "      <td>0.053251</td>\n",
       "      <td>1.110038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>5.961930</td>\n",
       "      <td>-14.501979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.463909</td>\n",
       "      <td>-437.016296</td>\n",
       "      <td>-217.351151</td>\n",
       "      <td>0.139118</td>\n",
       "      <td>1.125285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>6.564612</td>\n",
       "      <td>-12.783777</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>19.348387</td>\n",
       "      <td>-410.421692</td>\n",
       "      <td>-201.418793</td>\n",
       "      <td>0.185096</td>\n",
       "      <td>1.132845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>6.265402</td>\n",
       "      <td>-13.813774</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>20.079176</td>\n",
       "      <td>-403.053497</td>\n",
       "      <td>-174.624084</td>\n",
       "      <td>0.110875</td>\n",
       "      <td>1.131778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>6.651017</td>\n",
       "      <td>-13.385007</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>20.036022</td>\n",
       "      <td>-414.343170</td>\n",
       "      <td>-210.031250</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>1.034264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>6.129722</td>\n",
       "      <td>-14.105814</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>20.235537</td>\n",
       "      <td>-404.914490</td>\n",
       "      <td>-188.718719</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>1.038202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>6.215006</td>\n",
       "      <td>-14.473124</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>20.688129</td>\n",
       "      <td>-426.984375</td>\n",
       "      <td>-200.247345</td>\n",
       "      <td>0.138559</td>\n",
       "      <td>1.137424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>5.878806</td>\n",
       "      <td>-14.110991</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>19.989796</td>\n",
       "      <td>-416.047058</td>\n",
       "      <td>-195.617355</td>\n",
       "      <td>0.104365</td>\n",
       "      <td>1.090051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>6.261392</td>\n",
       "      <td>-14.368805</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>20.630194</td>\n",
       "      <td>-423.091370</td>\n",
       "      <td>-204.134811</td>\n",
       "      <td>0.225781</td>\n",
       "      <td>1.196190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>6.248044</td>\n",
       "      <td>-14.264328</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>20.512371</td>\n",
       "      <td>-422.577087</td>\n",
       "      <td>-200.357742</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>1.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>6.134273</td>\n",
       "      <td>-15.214307</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>21.348577</td>\n",
       "      <td>-434.970795</td>\n",
       "      <td>-207.323929</td>\n",
       "      <td>0.260710</td>\n",
       "      <td>1.257653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>6.348071</td>\n",
       "      <td>-14.423808</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>20.771879</td>\n",
       "      <td>-439.413269</td>\n",
       "      <td>-220.476562</td>\n",
       "      <td>0.254987</td>\n",
       "      <td>1.257538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=803, training_loss=0.24074620508808053, metrics={'train_runtime': 20533.4526, 'train_samples_per_second': 0.626, 'train_steps_per_second': 0.039, 'total_flos': 0.0, 'train_loss': 0.24074620508808053, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1204a809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:58:24.987663Z",
     "start_time": "2024-02-17T11:58:22.909947Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"dpo_mistral_1\") # Local saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f941512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T12:06:53.280634Z",
     "start_time": "2024-02-17T12:05:00.842037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 17.95 out of 31.27 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 52.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"dpo_mistral_full\", tokenizer, save_method = \"merged_16bit\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0999086",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55687416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:41:37.617145Z",
     "start_time": "2024-02-24T12:41:37.606515Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d47c9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:42:00.965335Z",
     "start_time": "2024-02-24T12:41:40.503391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7. FA = False.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n",
      "Unsloth 2024.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "#load model if needed\n",
    "dpo_model, dpo_tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"/mnt/d/Deep_learning/LLM/DPO/dpo_mistral_1/\", # YOUR DPO MODEL DIRECTORY\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "        cache_dir = \"cached\"\n",
    "    )\n",
    "FastLanguageModel.for_inference(dpo_model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5007fed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:42:11.476163Z",
     "start_time": "2024-02-24T12:42:06.994742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.2\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7. FA = False.\n",
      " \"-____-\"     Apache 2 free license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` attribute will be overwritten with the one you passed to `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "sft_model, sft_tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"/mnt/d/Deep_learning/LLM/DPO/sft_mistral_1/checkpoint-100\", # YOUR SFT MODEL DIRECTORY\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "        cache_dir = \"cached\"\n",
    "    )\n",
    "FastLanguageModel.for_inference(sft_model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e9e30d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:42:13.886200Z",
     "start_time": "2024-02-24T12:42:13.883871Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_prompt_template(data):\n",
    "    prefix_text = 'Below is an instruction that describes a task. Write a response that ' \\\n",
    "               'appropriately completes the request.\\n\\n'\n",
    "    # Samples with additional context into.\n",
    "    if len(data['system'])>0:\n",
    "        prompt = f\"\"\"[INST]{data['system']} {data[\"question\"]} [/INST]\"\"\"\n",
    "        \n",
    "    # Without\n",
    "    else:\n",
    "        prompt = f\"\"\"[INST]{prefix_text} {data[\"question\"]} [/INST]\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5847ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T12:42:16.096374Z",
     "start_time": "2024-02-24T12:42:16.093910Z"
    }
   },
   "outputs": [],
   "source": [
    "text_streamer = TextStreamer(dpo_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608d4514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:51:37.436733Z",
     "start_time": "2024-02-24T14:51:37.417403Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = dpo_tokenizer(\n",
    "[\n",
    "    apply_prompt_template({\n",
    "        'system' :  \"\", # instruction\n",
    "        'question' : \"how can i develop a habit of drawing daily ?\", # input\n",
    "    })\n",
    "], return_tensors = \"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f49626d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:51:47.214054Z",
     "start_time": "2024-02-24T14:51:40.640237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " how can i develop a habit of drawing daily ? [/INST]To develop a habit of drawing daily, follow these steps:\n",
      "\n",
      "1. Set a specific goal: Decide on a particular drawing style or subject matter to focus on. This will help you stay motivated and focused.\n",
      "\n",
      "2. Create a schedule: Set aside a specific time each day for drawing. Make sure it is a time when you are most productive and least likely to be disturbed.\n",
      "\n",
      "3. Start small: Begin with a manageable amount of time each day, such as 15 minutes, and gradually increase the duration as you become more comfortable with the routine.\n",
      "\n",
      "4. Keep a sketchbook handy: Always carry a sketchbook with you to capture ideas and inspiration whenever they strike.\n",
      "\n",
      "5. Find a drawing buddy: Join a local art group or connect with other artists online to share ideas, tips, and encouragement.\n",
      "\n",
      "6. Track progress: Keep a record of your daily drawing activities. This will help you stay accountable and monitor your progress. </s>\n"
     ]
    }
   ],
   "source": [
    "print('DPO answer: ')\n",
    "_ = dpo_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21590ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:52:12.993992Z",
     "start_time": "2024-02-24T14:52:05.540606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " how can i develop a habit of drawing daily ? [/INST]1. Set a specific goal: Decide on a specific goal for drawing daily. This could be to draw a certain number of minutes each day, or to draw a certain number of drawings each week.\n",
      "2. Create a schedule: Set aside a specific time each day to draw. This could be in the morning, during lunch, or in the evening.\n",
      "3. Make it a routine: Make drawing a daily routine. This could be by setting aside a specific time each day, or by creating a specific drawing space.\n",
      "4. Find a drawing community: Join a drawing community to get inspiration and support. This could be an online community, or a local drawing group.\n",
      "5. Keep track of progress: Keep track of progress by taking photos or keeping a journal. This will help to see how far you have come and to stay motivated.\n",
      "6. Stay consistent: Stay consistent with the daily drawing routine. This will help to build the habit and to see progress.\n",
      "7. Find inspiration: Find inspiration by looking at other artists' work, or by exploring different drawing techniques.\n",
      "8. Take breaks: Take breaks when needed. This will help to avoid burnout and to keep the drawing routine fresh. </s>\n"
     ]
    }
   ],
   "source": [
    "print('SFT answer: ')\n",
    "_ = sft_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695194af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:52:22.405286Z",
     "start_time": "2024-02-24T14:52:22.403050Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = dpo_tokenizer(\n",
    "[\n",
    "    apply_prompt_template({\n",
    "        'system' :  \"\", # instruction\n",
    "        'question' : \"Which animal has two hands, a hyrax or a dog ?\", # input\n",
    "    })\n",
    "], return_tensors = \"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7456b1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:52:24.820067Z",
     "start_time": "2024-02-24T14:52:24.305848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " Which animal has two hands, a hyrax or a dog ? [/INST]Neither a hyrax nor a dog has two hands. </s>\n"
     ]
    }
   ],
   "source": [
    "print('DPO answer: ')\n",
    "_ = dpo_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8823bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:52:33.712299Z",
     "start_time": "2024-02-24T14:52:33.391420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " Which animal has two hands, a hyrax or a dog ? [/INST]A hyrax has two hands.</s>\n"
     ]
    }
   ],
   "source": [
    "print('SFT answer: ')\n",
    "_ = sft_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d598bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:52:56.420697Z",
     "start_time": "2024-02-24T14:52:56.402542Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = dpo_tokenizer(\n",
    "[\n",
    "    apply_prompt_template({\n",
    "        'system' :  \"Continue the fibonnaci sequence.\", # instruction\n",
    "        'question' : \"1, 1, 2, 3, 5, 8\", # input\n",
    "    })\n",
    "], return_tensors = \"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bace1c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:53:03.575982Z",
     "start_time": "2024-02-24T14:52:58.273556Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO answer: \n",
      "<s> [INST]Continue the fibonnaci sequence. 1, 1, 2, 3, 5, 8 [/INST]13 \n",
      "\n",
      "# Explanation \n",
      "# Fibonacci sequence is generated by adding two previous numbers. Here are the inputs Given sequence: 1, 1, 2, 3, 5, 8 [/INST]\"\"\"\n",
      "Continue the fibonacci sequence. \n",
      "\n",
      "Given sequence: 1, 1, 2, 3, 5, 8 \n",
      "\"\"\"\n",
      "\n",
      "def continue_fibonacci_sequence(sequence):\n",
      "   # Calculate the next number in the sequence\n",
      "   next_number = sequence[-1] + sequence[-2]\n",
      "   \n",
      "   return next_number\n",
      "\n",
      "sequence = [1, 1, 2, 3, 5, 8]\n",
      "print(continue_fibonacci_sequence(sequence)) </s>\n"
     ]
    }
   ],
   "source": [
    "print('DPO answer: ')\n",
    "_ = dpo_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ec7d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:53:19.980122Z",
     "start_time": "2024-02-24T14:53:12.258866Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT answer: \n",
      "<s> [INST]Continue the fibonnaci sequence. 1, 1, 2, 3, 5, 8 [/INST]1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39088169, 63245986, 102334155\n"
     ]
    }
   ],
   "source": [
    "print('SFT answer: ')\n",
    "_ = sft_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e89642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:53:33.052100Z",
     "start_time": "2024-02-24T14:53:33.049939Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = dpo_tokenizer(\n",
    "[\n",
    "    apply_prompt_template({\n",
    "        'system' :  \"\", # instruction\n",
    "        'question' : \"What is a famous tall tower in Paris?\", # input\n",
    "    })\n",
    "], return_tensors = \"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661c45c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:53:36.597602Z",
     "start_time": "2024-02-24T14:53:35.473965Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " What is a famous tall tower in Paris? [/INST]The Eiffel Tower is a famous tall tower in Paris. It is an iconic landmark and tourist attraction, known for its unique design and impressive height. </s>\n"
     ]
    }
   ],
   "source": [
    "print('DPO answer: ')\n",
    "_ = dpo_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69b342f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-24T14:53:48.962229Z",
     "start_time": "2024-02-24T14:53:47.554403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT answer: \n",
      "<s> [INST]Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      " What is a famous tall tower in Paris? [/INST]The Eiffel Tower is a famous tall tower in Paris. It was built in 1889 and is 324 meters tall. It is one of the most popular tourist attractions in the world.</s>\n"
     ]
    }
   ],
   "source": [
    "print('SFT answer: ')\n",
    "_ = sft_model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a13007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba49473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "327px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
